CXX_STD = CXX17

LLAMA_DIR    = third_party/llama.cpp
LLAMA_BUILD  = $(LLAMA_DIR)/build
LLAMA_LIBDIR = $(LLAMA_BUILD)/lib
LLAMA_LIB    = $(LLAMA_LIBDIR)/libllama.a

# headers
PKG_CPPFLAGS += -I$(LLAMA_DIR)/include -I$(LLAMA_DIR)/ggml/include

# link order is critical: ggml-base -> ggml-cpu -> ggml -> llama
PKG_LIBS += -L$(LLAMA_LIBDIR) \
             -l:ggml-base.a \
             -l:ggml-cpu.a \
             -l:ggml.a \
             -lllama \
             -lwinmm -lws2_32 -fopenmp

all: $(LLAMA_LIB) $(SHLIB)

$(LLAMA_LIB):
	@echo "Configuring llama.cpp (CPU-only, MinGW) via CMake..."
	@cmake -S $(LLAMA_DIR) -B $(LLAMA_BUILD) -G "MinGW Makefiles" \
	  -DCMAKE_BUILD_TYPE=Release \
	  -DBUILD_SHARED_LIBS=OFF \
	  -DLLAMA_BUILD_TESTS=OFF \
	  -DLLAMA_BUILD_EXAMPLES=OFF \
	  -DLLAMA_BUILD_SERVER=OFF \
	  -DLLAMA_CUDA=OFF \
	  -DLLAMA_METAL=OFF \
	  -DGGML_METAL=OFF \
	  -DGGML_BLAS=OFF \
	  -DCMAKE_C_FLAGS="-DWINVER=0x0601 -D_WIN32_WINNT=0x0601" \
	  -DCMAKE_CXX_FLAGS="-DWINVER=0x0601 -D_WIN32_WINNT=0x0601" \
	  -DCMAKE_ARCHIVE_OUTPUT_DIRECTORY=$(abspath $(LLAMA_LIBDIR)) \
	  -DCMAKE_LIBRARY_OUTPUT_DIRECTORY=$(abspath $(LLAMA_LIBDIR))
	@echo "Building libllama (and ggml) with MinGW..."
	@cmake --build $(LLAMA_BUILD) --config Release --target llama -j

.PHONY: clean
clean:
	@rm -f *.o *.a *.dll *.dll.a

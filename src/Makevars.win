CXX_STD = CXX17

LLAMA_DIR    = third_party/llama.cpp
LLAMA_BUILD  = $(LLAMA_DIR)/build
LLAMA_LIBDIR = $(LLAMA_BUILD)/lib
LLAMA_LIB    = $(LLAMA_LIBDIR)/libllama.a

# headers
PKG_CPPFLAGS += -I$(LLAMA_DIR)/include -I$(LLAMA_DIR)/ggml/include

# Correct filenames + correct order (left->right resolution):
# llama depends on ggml*, so ggml* must be to the RIGHT of libllama.a
# When BLAS is enabled, include ggml-blas and link OpenBLAS (static) + Fortran runtimes.
PKG_LIBS += \
  $(LLAMA_LIB) \
  $(LLAMA_LIBDIR)/ggml.a \
  $(LLAMA_LIBDIR)/ggml-cpu.a \
  $(LLAMA_LIBDIR)/ggml-base.a \
  $(LLAMA_LIBDIR)/ggml-blas.a \
  -static-libgcc -static-libstdc++ \
  -Wl,-Bstatic -lopenblas -static-libgfortran -static-libquadmath -Wl,-Bdynamic \
  -lpthread -lwinmm -lws2_32 -fopenmp

all: $(LLAMA_LIB) $(SHLIB)

$(LLAMA_LIB):
	@echo "Configuring llama.cpp (CPU-only, MinGW) via CMake..."
	@cmake -S $(LLAMA_DIR) -B $(LLAMA_BUILD) -G "MinGW Makefiles" \
	  -DCMAKE_BUILD_TYPE=Release \
	  -DBUILD_SHARED_LIBS=OFF \
	  -DLLAMA_BUILD_TESTS=OFF \
	  -DLLAMA_BUILD_EXAMPLES=OFF \
	  -DLLAMA_BUILD_SERVER=OFF \
	  -DLLAMA_CUDA=OFF \
	  -DLLAMA_METAL=OFF \
    -DGGML_METAL=OFF \
    -DGGML_BLAS=ON -DGGML_BLAS_VENDOR=OpenBLAS \
    -DGGML_STATIC=ON \
    -DLLAMA_STATIC=ON \
	  -DCMAKE_C_FLAGS="-DWINVER=0x0601 -D_WIN32_WINNT=0x0601" \
	  -DCMAKE_CXX_FLAGS="-DWINVER=0x0601 -D_WIN32_WINNT=0x0601" \
	  -DCMAKE_ARCHIVE_OUTPUT_DIRECTORY=$(abspath $(LLAMA_LIBDIR)) \
	  -DCMAKE_LIBRARY_OUTPUT_DIRECTORY=$(abspath $(LLAMA_LIBDIR))
	@echo "Building libllama (and ggml) with MinGW..."
	@cmake --build $(LLAMA_BUILD) --config Release --target llama -j

.PHONY: clean
clean:
	@rm -f *.o *.a *.dll *.dll.a
